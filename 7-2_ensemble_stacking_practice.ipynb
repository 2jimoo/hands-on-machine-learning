{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bc2e2b3",
   "metadata": {},
   "source": [
    "# 8번\n",
    "- MINIST 데이터를 훈련세트 50000개, 검증세트 10000개, 테스트 10000개로 분할\n",
    "- 랜덤 포레스트, 엑스트라트리, SVM 등으로 훈련\n",
    "- 직접 투표 또는 간접투표로 앙상블\n",
    "- 개별 분류기와 앙상블 결과를 테스트 세트로 성능 비교\n",
    "- https://github.com/rickiepark/handson-ml2/blob/master/07_ensemble_learning_and_random_forests.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96121b",
   "metadata": {},
   "source": [
    "##### MINIST 데이터를 훈련세트 50000개, 검증세트 10000개, 테스트 10000개로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b2c8083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist= fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y, X_test, y_test= mnist['data'][:60000], mnist['target'][:60000], mnist['data'][60000:], mnist['target'][60000:]\n",
    "\n",
    "#stratify: default=None. classification을 다룰 때 성능차이가 많이 나는 옵션(데이터 편향 방지)\n",
    "#stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지. \n",
    "X_train,X_val, y_train, y_val=train_test_split(X, y, test_size=10000,stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "834c3ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n",
      "(50000, 784) (50000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9f34743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "#fit_transform 학습+변환, transform 변환만\n",
    "X_train= pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a247af26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 154) (10000,)\n",
      "(50000, 154) (50000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "#차원 축소는 언제나 훈련 시간을 줄여주지 못합니다. 데이터셋, 모델, 훈련 알고리즘에 따라 달라집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf791d4",
   "metadata": {},
   "source": [
    "##### 랜덤 포레스트, 엑스트라트리, SVM 등으로 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d44dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def early_stopping(model):\n",
    "    min_val_error=float('inf')\n",
    "    error_goning_up= 0\n",
    "    for n_estimators in range(10, 200, 10):\n",
    "        print(n_estimators)\n",
    "        model.n_estimators= n_estimators\n",
    "        model.fit(X_train, y_train)\n",
    "        #y_pred= model.predict(X_val)\n",
    "        #val_error= mean_squared_error(y_val, y_pred)\n",
    "        val_error= model.score(X_val, y_val)\n",
    "        if val_error < min_val_error:\n",
    "            min_val_error= val_error\n",
    "            error_going_up= 0\n",
    "        else:\n",
    "            error_going_up += 1\n",
    "            if error_going_up == 5:\n",
    "                break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ab92b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:584: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:584: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.8154960317460317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost\n",
    "\n",
    "rnd_clf=RandomForestClassifier(\n",
    "    max_leaf_nodes=16,\n",
    "    n_jobs=-1, \n",
    "    warm_start=True, \n",
    "    oob_score=True,\n",
    "    bootstrap=True)\n",
    "rnd_clf=early_stopping(rnd_clf)\n",
    "print(rnd_clf.__class__.__name__, rnd_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "ada_clf=AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    algorithm=\"SAMME.R\",\n",
    "    learning_rate=0.2\n",
    ")\n",
    "ada_clf=early_stopping(ada_clf)\n",
    "print(ada_clf.__class__.__name__, ada_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf=GradientBoostingClassifier(\n",
    "    max_depth=2,\n",
    "    warm_start=True\n",
    ")\n",
    "gb_clf=early_stopping(gb_clf)\n",
    "print(gb_clf.__class__.__name__, gb_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf= xgboost.XGBClassifier( \n",
    "    max_depth=2,\n",
    "    n_jobs=-1, )\n",
    "xgb_clf.fit(X_train, y_train, evel_set=[(X_val, y_val)], early_stopping_rounds=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858fd29",
   "metadata": {},
   "source": [
    "##### 개별 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6286dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy_score(model_list):\n",
    "    for model in model_list:\n",
    "        y_pred= model.predict(X_test)\n",
    "        score= accuracy_score(y_test, y_pred)\n",
    "        print(model.__class__.__name__, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print_accuracy_score([rnd_clf, ext_clf, ada_clf, gb_clf, xgb_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261db2c",
   "metadata": {},
   "source": [
    "##### 보팅 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vot_hard_clf= VotingClassifier(\n",
    "    estimators=[(\"rnd_clf\",rnd_clf),(\"ada_clf\",ada_clf),(\"gb_clf\",gb_clf),(\"xgb_clf\",xgb_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "vot_soft_clf= VotingClassifier(\n",
    "    estimators=[(\"rnd_clf\",rnd_clf),(\"ada_clf\",ada_clf),(\"gb_clf\",gb_clf),(\"xgb_clf\",xgb_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "print_accuracy_score([vot_hard_clf, vot_soft_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222230b9",
   "metadata": {},
   "source": [
    "# 9번\n",
    "- 8번의 검증세트 결과로 새로운 훈련세트(샘플=각 분류기의 예측, 타겟=클래스) 생성\n",
    "- 블렌더를 그 훈련세트로 훈련\n",
    "    - MLPClassifier,RandomForestClassifier등을 블렌더 용도로 쓸 수 있다.\n",
    "- 투표분류기와 블렌더의 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49328fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.3-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from xgboost) (1.24.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from xgboost) (1.9.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "    \n",
    "stk_clf = StackingClassifier(\n",
    "    estimators=[rnd_clf, ext_clf, ada_clf, gb_clf, xgb_clf], \n",
    "    final_estimator=MLPClassifier()\n",
    ")\n",
    "\n",
    "print_accuracy_score([stk_clf])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
